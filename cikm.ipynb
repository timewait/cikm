{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from src.model import get_model_instance\n",
    "from src.dataset import get_data_iterator\n",
    "from src import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths_in_dirs(dirs, shuffle=False):\n",
    "    paths = []\n",
    "    for dir in dirs:\n",
    "        paths.extend(list(map(lambda filename: os.path.join(dir, filename), os.listdir(dir))))\n",
    "    if shuffle is True:\n",
    "        random.shuffle(paths)\n",
    "    return paths\n",
    "\n",
    "\n",
    "def get_dataset_from_dirs(data_dirs, batch_size, is_train=True):\n",
    "\n",
    "    def parse_exmp(serial_exmp):\n",
    "        feats = tf.parse_single_example(serial_exmp, features={'inp': tf.VarLenFeature(tf.int64),\n",
    "                                                               'resp': tf.VarLenFeature(tf.int64),\n",
    "                                                               'label': tf.FixedLenFeature([1], tf.int64)})\n",
    "        inp = tf.sparse_tensor_to_dense(feats['inp'])[:100]\n",
    "        resp = tf.sparse_tensor_to_dense(feats['resp'])[:100]\n",
    "        label = feats['label']\n",
    "        return inp, resp, label\n",
    "\n",
    "    paths = get_paths_in_dirs(data_dirs)\n",
    "    dataset = tf.data.TFRecordDataset(paths, 'GZIP').map(parse_exmp)\n",
    "    padded_shapes = tuple(dataset.output_shapes)\n",
    "    padded_values = tuple([tf.convert_to_tensor(0, tf.int64)] * len(padded_shapes))\n",
    "    if is_train is True:\n",
    "        dataset = dataset.shuffle(buffer_size=20000).repeat(None)\n",
    "    dataset = dataset.padded_batch(batch_size, padded_shapes, padded_values).prefetch(10)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('D_hidden_sizes', [512]), ('activation', 'tanh'), ('debug', False), ('decay_rate', 0.99), ('decay_steps', 100000), ('dot_inp_dnn_sizes', [-1]), ('dot_resp_dnn_sizes', [-1]), ('embed_dim', 256), ('encoder_type', 'dan'), ('experiment_dir', 'experiment/maga'), ('learning_rate', 0.001), ('max_epoch', 10000000), ('max_seqlen', 100), ('model_type', 'dot_product'), ('optimizer', 'adam'), ('steps_per_checkpoint', 20), ('steps_per_eval', 20), ('steps_per_info', 10), ('train_batch_size', 256), ('train_dirs', ['data/tfrecord/train']), ('val_batch_size', 256), ('val_dirs', ['data/tfrecord/val']), ('vocab_size', 5744)]\n"
     ]
    }
   ],
   "source": [
    "hparams = util.load_hparams(\"config/maga.yaml\")\n",
    "print hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data\n",
    "train_dataset = get_dataset_from_dirs(hparams.train_dirs, hparams.train_batch_size, is_train=True)\n",
    "val_dataset = get_dataset_from_dirs(hparams.val_dirs, hparams.val_batch_size, is_train=False)\n",
    "iterator = tf.data.Iterator.from_structure(train_dataset.output_types, train_dataset.output_shapes)\n",
    "inp, resp, label = iterator.get_next()\n",
    "train_iter_init_op = iterator.make_initializer(train_dataset)\n",
    "val_iter_init_op = iterator.make_initializer(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4423 1271   32 2117 2532 3967 5477 3092 4873 2211 2583 3652 5069    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[5702 4882   24 4331 3092 2669 4000 4971    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "[0]\n",
      "(256, 28)\n",
      "(256, 19)\n",
      "(256, 1)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(train_iter_init_op)\n",
    "    sess.run(val_iter_init_op)\n",
    "    i = sess.run(inp)\n",
    "    r = sess.run(resp)\n",
    "    l = sess.run(label)\n",
    "    print i[1]\n",
    "    print r[1]\n",
    "    print l[1]\n",
    "    print i.shape\n",
    "    print r.shape\n",
    "    print l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
